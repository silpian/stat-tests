{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm, chi2, binom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilcoxon Signed Rank Test\n",
    "Let\n",
    "    $$W = \\sum \\text{sgn} (x_i - y_i) R_i$$\n",
    "be the signed rank sum.\n",
    "\n",
    "Note that $R_i$ is the positive number between $1$ and $n$ where $n$ is the sample size, ordered from lowest absolute value at $1$ to highest absolute value at $n$. For example, given the array of differences\n",
    "$$[-3, 1, 2, 2]$$\n",
    "we have $R_1 = 4, R_2 = 1, R_3 = R_4 = 2.5$ where $R_3, R_4$ are each incremented by half because they share the same place.\n",
    "\n",
    "Then\n",
    "    $$\\frac{W - 0}{\\sqrt{\\frac{n(n+1)(2n+1)}{6}}} \\sim N(0, 1).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon_signed_rank_sum(x):\n",
    "    \"\"\"\n",
    "    Given a numpy 1 x n array of the differences, calculate the signed rank sum\n",
    "    Note that the array of differences is equal to {x_i - y_i} in the above equation\n",
    "    \"\"\"\n",
    "    temp = np.absolute(x).argsort()\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(len(x))\n",
    "    ranks = ranks + 1\n",
    "    signed_indices = np.where(x > 0, 1, -1)\n",
    "    signed_ranks = np.multiply(signed_indices, ranks)\n",
    "    return np.sum(signed_ranks)\n",
    "\n",
    "def wilcoxon_test_statistic(x):\n",
    "    \"\"\"\n",
    "    Given a numpy 1 x n array of the differences, calculate the test statistic\n",
    "    \"\"\"\n",
    "    n = np.size(x)\n",
    "    return wilcoxon_signed_rank_sum(x)/math.sqrt(n*(n+1)*(2*n+1)/6)\n",
    "\n",
    "def wilcoxon_p_val(x):\n",
    "    # p-value = P(|Z| >= wilcoxon test statistic) = 2*P(Z <= -abs(wilcoxon test statistic))\n",
    "    # by symmetry of the normal distribution\n",
    "    return 2*norm.cdf(-abs(wilcoxon_test_statistic(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-13.2, -10.5, -10.5,  -9.2,  -8.3,  -7.7,  -5.9,  -5.5,  -4.6,\n",
    "        -3.8,  -3.2,  -1. ,  -0.1,   0.4,   5.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003772239574473987"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_p_val(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square Goodness of Fit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_goodness_of_fit_p_val(observed, h0_parameters):\n",
    "    \"\"\"\n",
    "    observed - (n, ) numpy array of the observed number of each class\n",
    "    parameters - (n, ) numpy array of the null hypothesis proportions for each class in the same order as 'observed'\n",
    "    \"\"\"\n",
    "    assert np.size(observed) == np.size(h0_parameters)\n",
    "    \n",
    "    num_of_categories = np.size(observed)\n",
    "    n = np.sum(observed)\n",
    "    expected = n*h0_parameters\n",
    "    normalized_matrix = (observed - expected)**2/expected\n",
    "    test_statistic = np.sum(normalized_matrix)\n",
    "    \n",
    "    # p-value = P(chi-square, df = n-1 >= test statistic)\n",
    "    return 1 - chi2.cdf(test_statistic, df=num_of_categories-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square Homogeneity/Independence Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df = (number of rows - 1)*(number of columns - 1) = 4\n",
      "h0_values:\n",
      "[[ 16.625   9.5   152.      7.125   4.75 ]\n",
      " [ 18.375  10.5   168.      7.875   5.25 ]]\n",
      "normalized_matrix:\n",
      "[[1.15131579 4.44736842 0.32236842 3.68640351 0.32894737]\n",
      " [1.04166667 4.02380952 0.29166667 3.33531746 0.29761905]]\n",
      "test statistic: 18.926482873851295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0008125174740349905"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chi2_homogeneity_test_statistic(array):\n",
    "    column_totals = array.sum(axis=0)\n",
    "    h0_col_proportions = column_totals/column_totals.sum()\n",
    "    row_totals = array.sum(axis=1).reshape(-1, 1) # reshape for broadcasting\n",
    "    h0_values = h0_col_proportions*row_totals\n",
    "    print(\"h0_values:\")\n",
    "    print(h0_values)\n",
    "    normalized_matrix = (np.square(array - h0_values)/h0_values)\n",
    "    print(\"normalized_matrix:\")\n",
    "    print(normalized_matrix)\n",
    "    test_statistic = normalized_matrix.sum()\n",
    "    print(\"test statistic: {}\".format(test_statistic))\n",
    "    return test_statistic\n",
    "\n",
    "def chi2_homogeneity_p_val(array):\n",
    "    \"\"\"\n",
    "    Given a numpy array, compute the p val of the homogeneity/independence of the variables.\n",
    "    High homogeneity/independence will have a low Chi-square value because the differences will be small.\n",
    "    Low homogeneity/independence will have a high Chi-square value because the differences will be large.\n",
    "    \"\"\"\n",
    "    df = (np.size(array, 0)-1)*(np.size(array, 1)-1)\n",
    "    print(\"df = (number of rows - 1)*(number of columns - 1) = {}\".format(df))\n",
    "    p_val = 1 - chi2.cdf(chi2_homogeneity_test_statistic(array), df=df)\n",
    "    return p_val\n",
    "\n",
    "x = np.array([[21, 16, 145, 2, 6], [14, 4, 175, 13, 4]])\n",
    "chi2_homogeneity_p_val(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x):\n",
    "    \"\"\"\n",
    "    x is a 2 x n array where n > 1 and each row is a sample of a different random variable\n",
    "    \"\"\"\n",
    "    sample_mean = x.mean(axis=1).reshape(2,1)\n",
    "    normalized_x = x - sample_mean.reshape(2,1)\n",
    "    covariance = (1/(np.size(x, 1)-1))*(normalized_x[0]*normalized_x[1]).sum()\n",
    "    return covariance\n",
    "    \n",
    "def pearson_correlation(x):\n",
    "    \"\"\"\n",
    "    x is a 2 x n array where n > 1 and the each row is a sample of a different random variable\n",
    "    \"\"\"\n",
    "    return covariance(x)/(np.std(x[0], ddof=1)*np.std(x[1], ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_mean(array, tail=0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    We assume population variance is unknown and use the t distribution and sample mean and variance \n",
    "    to estimate a confidence interval for the population mean.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound,\n",
    "              0, then two-tailed\n",
    "              1, then one-tailed upper bound\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    mean = np.mean(array)\n",
    "    s = np.std(array, ddof=1)\n",
    "    n = np.size(array, 0)\n",
    "    \n",
    "    divisor_of_alpha = 2-abs(tail)\n",
    "    test_statistic = t.ppf(1-alpha/divisor_of_alpha, df=n-1)*s/math.sqrt(n)\n",
    "    coefficient_vector = np.array([-1, 1])\n",
    "    \n",
    "    if tail == -1:\n",
    "        coefficient_vector = np.array([-1, np.inf])\n",
    "    elif tail == 1:\n",
    "        coefficient_vector = np.array([-np.inf, 1])\n",
    "        \n",
    "    return mean + coefficient_vector*test_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038415512858004486"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_p_val_array(array, h0_mean, tail=0):\n",
    "    \"\"\"\n",
    "    Given a numpy array of iid samples from a normal distribution and h0 mean, determine the p-value.\n",
    "    \"\"\"\n",
    "    array = np.array(array)\n",
    "    return mean_p_val(np.mean(array), np.size(array), np.std(array, ddof=1), h0_mean, tail=tail)\n",
    "\n",
    "def mean_p_val(sample_mean, sample_size, std, h0_mean, std_is_pop_std=False, tail=0):\n",
    "    \"\"\"\n",
    "    We assume the population is distributed under a normal distribution and determine the p-value.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound,\n",
    "              0, then two-tailed\n",
    "              1, then one-tailed upper bound\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    \n",
    "    divisor_of_alpha = 2-abs(tail)\n",
    "    test_statistic = (sample_mean - h0_mean)/(std/math.sqrt(sample_size))\n",
    "    p_val = 1 # set arbitrary value for p-val\n",
    "    \n",
    "    if tail == -1:\n",
    "        # p-val = P(t <= test_statistic)\n",
    "        if std_is_pop_std:\n",
    "            p_val = norm.cdf(test_statistic)\n",
    "        else: \n",
    "            p_val = t.cdf(test_statistic, df=sample_size-1)\n",
    "    elif tail == 0:\n",
    "        # p-val = P(|t| >= |test_statistic|) = 2*P(t <= -|test_statistic)\n",
    "        # by the symmetry of the t distribution\n",
    "        if std_is_pop_std:\n",
    "            p_val = 2*norm.cdf(-abs(test_statistic))\n",
    "        else:\n",
    "            p_val = 2*t.cdf(-abs(test_statistic), df=sample_size-1)\n",
    "    elif tail == 1:\n",
    "        # p-val = P(t >= test_statistic)\n",
    "        if std_is_pop_std:\n",
    "            p_val = 1 - norm.cdf(test_statistic)\n",
    "        else:\n",
    "            p_val = 1 - t.cdf(test_statistic, df=sample_size-1)\n",
    "        \n",
    "    return p_val\n",
    "\n",
    "mean_p_val(26.33, 16, 2.8, 25, tail=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Difference of Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Difference of Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two samples $x, y$ with standard deviation $s_x, s_y$ and sample size $n_x, n_y$, the test statistic $T$ is\n",
    "    $$T = \\frac{\\bar{x} - \\bar{y}}{\\sqrt{\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}}}$$\n",
    "where $T \\sim t_{\\text{df} = \\nu}$ and $\\nu$ is the Welch's degree of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch's $\\nu$ Degrees of Freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two samples $x, y$ with standard deviation $s_x, s_y$ and sample size $n_x, n_y$, respectively, Welch's $\\nu$ degrees of freedom is defined as\n",
    "$$\\nu = \\frac{(\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y})^2}{\\frac{s_x^4}{n_x^2(n_x - 1)} + \\frac{s_y^4}{n_y^2(n_y - 1)}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_df(s1, s2, n1, n2):\n",
    "    return math.floor((s1**2/n1 + s2**2/n2)**2/((1/(n1-1))*(s1**2/n1)**2 + (1/(n2-1))*(s2**2/n2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_means_p_val(x1_mean, x2_mean, n1, n2, s1, s2, tail=0):\n",
    "    \"\"\"\n",
    "    We assume the population is a normal distribution and determine the p-value.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound: x1_mean - x2_mean < 0,\n",
    "              0, then two-tailed: x1_mean - x2_mean != 0,\n",
    "              1, then one-tailed upper bound: x1_mean - x2_mean > 0,\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    test_statistic = (x1_mean - x2_mean)/math.sqrt(s1**2/n1 + s2**2/n2)\n",
    "    p_val = 1 # set arbitrary value for p-val\n",
    "    \n",
    "    df = math.floor(welch_df(s1, s2, n1, n2))\n",
    "    \n",
    "    if tail == -1:\n",
    "        # p-val = P(t <= test_statistic)\n",
    "        p_val = t.cdf(test_statistic, df=df)\n",
    "    elif tail == 0:\n",
    "        # p-val = P(|t| >= |test_statistic|) = 2*P(t <= -|test_statistic)\n",
    "        # by the symmetry of the t distribution\n",
    "        p_val = 2*t.cdf(-abs(test_statistic), df=df)\n",
    "    elif tail == 1:\n",
    "        # p-val = P(t >= test_statistic)\n",
    "        p_val = 1 - t.cdf(test_statistic, df=df)\n",
    "        \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_variance(array, tail=0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    We use the Chi-square distribution to estimate a confidence interval for the population variance.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound,\n",
    "              0, then two-tailed\n",
    "              1, then one-tailed upper bound\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    s = np.std(array, ddof=1)\n",
    "    n = np.size(array, 0)\n",
    "    \n",
    "    divisor_of_alpha = 2-abs(tail)\n",
    "    lower_bound = (n-1)*s**2/chi2.ppf(1-alpha/divisor_of_alpha, df=n-1)\n",
    "    upper_bound = (n-1)*s**2/chi2.ppf(alpha/divisor_of_alpha, df=n-1)\n",
    "    coefficient_vector = np.array([1,1])\n",
    "    \n",
    "    if tail == -1:\n",
    "        coefficient_vector = np.array([1, np.inf])\n",
    "    elif tail == 1:\n",
    "        coefficient_vector = np.array([0, 1])\n",
    "        \n",
    "    return coefficient_vector * np.array([lower_bound, upper_bound])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reject the null hypothesis if the p-value is less than or equal to $\\alpha$. While the p-values for the left and right tail are obvious, the two-tailed test requires taking the minimum of the left and right tails and then doubling it.\n",
    "\n",
    "If our confidence level is $\\alpha$, then we reject $H_0$ if our test statistic $X^2$ is in one of either two scenarios:\n",
    "$$X^2 \\leq \\mathcal{X}^2_{\\alpha/2} \\iff P(\\mathcal{X}^2 \\leq X^2) \\leq \\frac{\\alpha}{2} \\iff 2P(\\mathcal{X}^2 \\leq X^2) \\leq \\alpha,$$\n",
    "or\n",
    "$$X^2 \\geq \\mathcal{X}^2_{\\alpha/2} \\iff P(\\mathcal{X}^2 \\geq X^2) \\leq \\frac{\\alpha}{2} \\iff 2P(\\mathcal{X}^2 \\geq X^2) \\leq \\alpha,$$\n",
    "where $\\mathcal{X}^2$ is a chi-square random variable with $n-1$ degrees of freedom where $n$ is the sample size.\n",
    "\n",
    "This can be summarized by rejecting $H_0$ if\n",
    "$$\\min(2P(\\mathcal{X}^2 \\leq X^2), 2P(\\mathcal{X}^2 \\geq X^2)) = 2\\min(P(\\mathcal{X}^2 \\leq X^2), P(\\mathcal{X}^2 \\geq X^2)) \\leq \\alpha.$$\n",
    "Thus we should define the p-value of the two tailed test as such\n",
    "    $$\\text{p-value} = 2\\min(P(\\mathcal{X}^2 \\leq X^2), P(\\mathcal{X}^2 \\geq X^2)).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_p_val(sample_variance, sample_size, h0_variance, tail=0):\n",
    "    \"\"\"\n",
    "    We assume the population is a normal distribution and determine the p-value.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound,\n",
    "              0, then two-tailed\n",
    "              1, then one-tailed upper bound\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    test_statistic = (sample_size -1)*sample_variance/h0_variance\n",
    "    p_val = 1 # set arbitrary value for p-val\n",
    "    \n",
    "    if tail == -1:\n",
    "        # p-val = P(chi-square <= test_statistic)\n",
    "        p_val = chi2.cdf(test_statistic, df=sample_size-1)\n",
    "    elif tail == 0:\n",
    "        # p-val = 2*min(P(chi-square <= test_statistic), P(chi-square >= test_statistic))\n",
    "        p_val = 2*min(chi2.cdf(test_statistic, df=sample_size-1), 1 - chi2.cdf(test_statistic, df=sample_size-1))\n",
    "    elif tail == 1:\n",
    "        # p-val = P(t >= test_statistic)\n",
    "        p_val = 1 - chi2.cdf(test_statistic, df=sample_size-1)\n",
    "        \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04032196, 1.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confidence_interval_proportion(p, n, tail=0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    We estimate a confidence interval for the population proportion.\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound,\n",
    "              0, then two-tailed\n",
    "              1, then one-tailed upper bound\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    divisor_of_alpha = 2-abs(tail)\n",
    "    test_statistic = norm.ppf(1-alpha/divisor_of_alpha)*math.sqrt(p*(1-p)/n)\n",
    "    coefficient_vector = np.array([-1, 1])\n",
    "    \n",
    "    if tail == -1:\n",
    "        coefficient_vector = np.array([-1, 1.1/(test_statistic)]) # 1.1 is arbitrary, the upper bound should always be 1\n",
    "    elif tail == 1:\n",
    "        coefficient_vector = np.array([0, 1])\n",
    "        \n",
    "    unbounded_ci = p + coefficient_vector*test_statistic\n",
    "    bounded_ci = -1*(unbounded_ci < 0)*unbounded_ci + unbounded_ci + -1*(unbounded_ci > 1)*(unbounded_ci-1)\n",
    "    return bounded_ci\n",
    "    \n",
    "confidence_interval_proportion(p=28/400, n=400, tail=-1, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Difference of Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for Difference of Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the standard error of the difference $p_1 - p_2$ is\n",
    "    $$\\sqrt{\\frac{\\hat{p_1} (1-\\hat{p_1})}{n_1} + \\frac{\\hat{p_2} (1-\\hat{p_2})}{n_2}},$$\n",
    "when we do the hypothesis test, we assume $p_1 = p_2$, and therefore need to change $\\hat{p_1}, \\hat{p_2}$ in the standard error to an average\n",
    "    $$\\hat{p} = \\frac{n_1 \\hat{p_1} + n_2 \\hat{p_2}}{n_1 + n_2}.$$\n",
    "Then our standard error becomes\n",
    "    $$\\sqrt{\\hat{p} (1-\\hat{p})(\\frac{1}{n_1} + \\frac{1}{n_2})}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_proportions_p_val(p1, p2, n1, n2, tail=0):\n",
    "    \"\"\"\n",
    "    \n",
    "    tail: if -1, then one-tailed lower bound: p1 - p2 < 0,\n",
    "              0, then two-tailed: p1 - p2 != 0,\n",
    "              1, then one-tailed upper bound: p1 - p2 > 0,\n",
    "    \"\"\"\n",
    "    assert tail in [-1, 0, 1]\n",
    "    \n",
    "    average_p = (n1*p1 + n2*p2)/(n1+n2)\n",
    "    test_statistic = (p1-p2)/math.sqrt(average_p*(1-average_p)*(1/n1 + 1/n2))\n",
    "    p_val = 1 # set arbitrary value for p-val\n",
    "    \n",
    "    if tail == -1:\n",
    "        # p-val = P(Z <= test_statistic)\n",
    "        p_val = norm.cdf(test_statistic)\n",
    "    elif tail == 0:\n",
    "        # p-val = P(|Z| >= |test_statistic|) = 2*P(Z <= -|test_statistic)\n",
    "        # by the symmetry of the normal distribution\n",
    "        p_val = 2*norm.cdf(-abs(test_statistic))\n",
    "    elif tail == 1:\n",
    "        # p-val = P(Z >= test_statistic)\n",
    "        p_val = 1 - norm.cdf(test_statistic)\n",
    "        \n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
